{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a264c4-d221-4e7a-8267-73eac5bffe57",
   "metadata": {},
   "source": [
    "**A scrapbook to explore librosa methods and how they impact our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc01e40-6b60-415a-a179-19c877fefde4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import the usual stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8691568-5070-44dd-bf1e-3d3187792d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5be72-45ae-4d82-8282-ffbe8235790a",
   "metadata": {},
   "source": [
    "## Getting data/wav files from (local) folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1326fe-3253-4f2c-aafe-37a8792c0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiphop', 'classical', 'blues', 'metal', 'jazz', 'country', 'pop', 'rock', 'disco', 'reggae']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "general_path = '../k_means_klang/raw_data/Data'\n",
    "print(list(os.listdir(f'{general_path}/genres_original/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44b85ff9-e8ef-45b1-9e37-dc5abfb0c1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.31913</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "3    -3.319597   50.206673     0.636965    37.31913    -0.619121   37.259739   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "3    -3.407448   31.949339  blues  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{general_path}/features_30_sec.csv')\n",
    "data.iloc[3:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f33627-f9c1-41b5-a1a4-08d8549679d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# A. Creating variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0782d6b-d164-4611-879b-1f529057745e",
   "metadata": {},
   "source": [
    "- Sound: sequence of vibrations in varying pressure strengths (y)\n",
    "- The sample rate (sr) is the number of samples of audio carried per second, measured in Hz or kHz\n",
    "- audio_file is the sound or y, but trimmed using a librosa function\n",
    "note: librosa.load()... This function loads an audio file.\n",
    "\n",
    "Example for this excercise is blues.00003.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a88bb220-e8f4-4a39-90d7-8bd08ac005e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661794,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use librosa.load to the sound and the sample rate \n",
    "y, sr = librosa.load(f'{general_path}/genres_original/blues/blues.00003.wav')\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f168a-1b37-4e30-aa38-dcf732cc42a2",
   "metadata": {},
   "source": [
    "**the method below** returns.. \n",
    "\n",
    "A trimmed version of the audio signal (i.e., without the silence at the beginning and end) which is reassigned back to y.\n",
    "A second output (usually the indices of the non-silent frames) is returned, but here it is ignored by assigning it to _."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cc22366-8fd4-43a1-a90a-62b65cb729a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661794"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using librosa.effects.trim \n",
    "audio_file, _ = librosa.effects.trim(y)\n",
    "\n",
    "audio_file.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87784f-6a96-45d3-8dfc-3f1a98ea2ebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# B. Understanding the Librosa functions needed to create the csv (for 30 sec wav files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b84e0d-9ba9-4bb1-b43f-51cdf0d58803",
   "metadata": {},
   "source": [
    "**the different features - 58 in total**\n",
    " 1. Zero Crossing Rate,  (mean and var)\n",
    " 2. Harmonics  (mean and var)\n",
    " 3. Perceptrual  (mean and var)\n",
    " 4. Tempo\n",
    " 5. Spectral Centroid  (mean and var)\n",
    " 6. Spectral Rolloff  (mean and var)\n",
    " 7. Spectral Bandwidth (mean and var)\n",
    " 8. Mel-Frequency Cepstral Coefficients (20 different coefficients) (mean and var)\n",
    " 9. Chroma (mean and var)\n",
    " 10. rms energy (mean and var)\n",
    " 11. lenghth of the audio file (audio_file.shape[0]) .\n",
    "\n",
    "*58 features in total*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cee5d-28d3-44cd-9481-dc6f38780181",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Zero Range \n",
    "- the rate at which the signal changes from positive to negative or back.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "093ee0e6-5a99-49eb-9394-d94730d37609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero crossing mean is: 0.03335932329395552\n",
      "Zero crossing var is: 0.03224647884332488\n"
     ]
    }
   ],
   "source": [
    "# Total zero_crossings in our 1 song \n",
    "zero_crossings = librosa.zero_crossings(audio_file, pad=False)\n",
    "# print(sum(zero_crossings))\n",
    "print('Zero crossing mean is:', np.mean(zero_crossings))\n",
    "print('Zero crossing var is:', np.var(zero_crossings))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e391f9-8627-40e8-bdf9-2c9dcb04fe3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Harmonics and 3. Perceptrual\n",
    "- Harmonics are characteristics that human ears can't distinguish (represents the sound color)\n",
    "- Perceptrual understanding shock wave represents the sound rhythm and emotion\n",
    " here we use librosa.effects.hpss on our y trimmed ie. our \"audio_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0335107-d345-4bc8-8e97-b6fd2d609d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harmony var is: 0.019055042\n",
      "harmony mean is: 3.6126078e-06\n",
      "harmony var is: 0.0027113643\n",
      "harmony mean is: -1.8110986e-05\n"
     ]
    }
   ],
   "source": [
    "y_harm, y_perc = librosa.effects.hpss(audio_file)\n",
    "print('harmony var is:', np.var(y_harm))\n",
    "print('harmony mean is:', np.mean(y_harm))\n",
    "\n",
    "print('perceptrual var is:', np.var(y_perc))\n",
    "print('perceptrual is:', np.mean(y_perc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d08ccf34-ba13-4c0f-b08d-815708e4ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_harm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db12de-342a-4916-a1cf-621b0f26811d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Tempo BMP (beats per minute)¶\n",
    "-  using librosa.beat.beat_track methond on audio_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7690a2c7-d443-4926-8e84-cfa5c7c0113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.02400914634146"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo_value, _ = librosa.beat.beat_track(y=audio_file, sr = sr)\n",
    "tempo_value.item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88f55-c993-4b41-83c6-93ff9d072af6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. Spectral Centroid\n",
    "- indicates where the ”centre of mass” for a sound is located and is calculated as the weighted mean of the frequencies present in the sound.\n",
    "- we use 'librosa.feature.spectral_centroid' method  (when visualizing we need to slice [0] because is a 2 dim list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93ba7bf2-1d80-4d2c-9b2d-b1dacdd5da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 694.20629018  696.33642143  659.9642591  ... 1008.04442371 1007.3869005\n",
      " 1124.11357557]\n",
      "spectral_centroids var is: 184366.00943826674\n",
      "spectral_centroids mean is: 1070.1534175250665\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Spectral Centroids\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=audio_file, sr=sr)[0]\n",
    "print(spectral_centroids)\n",
    "\n",
    "print('spectral_centroids var is:', np.var(spectral_centroids))\n",
    "print('spectral_centroids mean is:', np.mean(spectral_centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84681ad-f213-4c42-8679-d86ae48393c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6. Spectral Rolloff\n",
    "-  is a measure of the shape of the signal. It represents the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies\n",
    "-  we will use 'librosa.feature.spectral_rolloff' method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8bad7862-fee0-4641-8527-bbf3d413f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral_rolloff var is: 1493077.8489404472\n",
      "spectral_rolloff mean is: 2184.8790286035382\n"
     ]
    }
   ],
   "source": [
    "spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_file, sr=sr)[0]\n",
    "spectral_rolloff\n",
    "\n",
    "print('spectral_rolloff var is:', np.var(spectral_rolloff))\n",
    "print('spectral_rolloff mean is:', np.mean(spectral_rolloff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e68a39-1210-4f18-9b0f-449f3ab72d3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 7. Spectral bandwidth\n",
    "- The spectral bandwidth measures the spread of the spectrum around its centroid (mean frequency), giving you an idea of how \"wide\" or \"narrow\" the distribution of energy is across frequencies. This can be useful in characterizing the timbre or texture of a sound.\n",
    "- we will use  method 'feature.spectral_bandwidth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dd136db4-7616-491b-b62f-fc42775a02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral bandwidth shape: (1, 1293)\n",
      "Mean spectral bandwidth (Hz): 1596.422564453577\n",
      "Var spectral bandwidth (Hz): 166551.84424342896\n"
     ]
    }
   ],
   "source": [
    "# Calculate the spectral bandwidth\n",
    "bandwidth = librosa.feature.spectral_bandwidth(y=audio_file, sr=sr)\n",
    "\n",
    "# Print the shape and a summary statistic (mean bandwidth)\n",
    "print(\"Spectral bandwidth shape:\", bandwidth.shape)\n",
    "print(\"Mean spectral bandwidth (Hz):\", np.mean(bandwidth))\n",
    "print(\"Var spectral bandwidth (Hz):\", np.var(bandwidth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce678276-0e3b-4dbb-936f-96986e20f4aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 8. Mel-Frequency Cepstral Coefficients:¶\n",
    "- ie. The timbre! \n",
    "- The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. It models the characteristics of the human voice.\n",
    "- we will use the librosa.feature.mfcc method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c1b6e02-bd4e-41f5-a12b-5e235c7c0b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfccs shape: (20, 1293)\n",
      "Mean of each MFCC coefficient: [-199.57513     150.0861        5.663404     26.855282      1.7700713\n",
      "   14.232647     -4.827845      9.286853     -0.75612015    8.134435\n",
      "   -3.200026      6.078081     -2.4784453    -1.0815871    -2.8744543\n",
      "    0.77399397   -3.3240693     0.63631064   -0.6159675    -3.405046  ]\n",
      "Variance of each MFCC coefficient: [5508.266     456.30908   257.10977   158.36111   267.97372   126.80741\n",
      "  155.94673    81.2703     92.3018     71.381836  110.269356   48.214516\n",
      "   56.776222   62.243008   51.609818   44.432903   50.218452   37.325726\n",
      "   37.257774   31.965254]\n"
     ]
    }
   ],
   "source": [
    "mfccs = librosa.feature.mfcc(y=audio_file, sr=sr)\n",
    "\n",
    "# we get 20 mfccs\n",
    "print('mfccs shape:', mfccs.shape)\n",
    "\n",
    "#now to calculate mean and var for each mfcc coefficient (ie. each row) \n",
    "mfcc_means = np.mean(mfccs, axis=1)\n",
    "mfcc_vars = np.var(mfccs, axis=1)\n",
    "\n",
    "print(\"Mean of each MFCC coefficient:\", mfcc_means)\n",
    "print(\"Variance of each MFCC coefficient:\", mfcc_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf26b3b-37b3-4804-bc64-94d03a7d8dde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 9. Chroma Frequencies¶\n",
    "- Chroma features are an interesting and powerful representation for music audio in which the entire spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma) of the musical octave.\n",
    "- we will use 'librosa.feature.chroma_stft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b9a8c79-c62c-4990-9c83-d67b6927f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromogram shape: (12, 133)\n"
     ]
    }
   ],
   "source": [
    "# Increase or decrease hop_length to change how granular you want your data to be\n",
    "hop_length = 5000\n",
    "\n",
    "# Chromogram\n",
    "chromagram = librosa.feature.chroma_stft(y = audio_file, sr=sr, hop_length=hop_length)\n",
    "print('Chromogram shape:', chromagram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "900f2056-27d0-423c-b80e-398b861130fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromagram var is: 0.094975464\n",
      "chromagram mean is: 0.42627874\n"
     ]
    }
   ],
   "source": [
    "print('chromagram var is:', np.var(chromagram))\n",
    "print('chromagram mean is:', np.mean(chromagram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448d72e-a40e-4777-b880-c4e1c8dce8b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10. RMS energy\n",
    "- RMS energy in the context of an audio signal is a measure of the signal's power. It’s calculated as the square root of the average of the squares of the amplitude values over a given time frame. This metric effectively represents the \"loudness\" or energy of the audio, smoothing out rapid fluctuations in amplitude to provide a stable measure of how strong the signal is on average. It's widely used in audio processing for tasks like volume normalization, dynamic range compression, and silence detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32ddbb6a-31a1-4176-86f2-b3582f205d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10660144 0.13829172 0.16152988 ... 0.01791866 0.01520183 0.01265691]]\n",
      "rms var is: 0.006347602\n",
      "rms mean is: 0.14104027\n"
     ]
    }
   ],
   "source": [
    "# Compute RMS values per frame\n",
    "rms_values = librosa.feature.rms(y=audio_file)\n",
    "print(rms_values)\n",
    "\n",
    "print('rms var is:', np.var(rms_values))\n",
    "print('rms mean is:', np.mean(rms_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5583501-1b3c-4008-a7ec-773d0ae2131b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Length \n",
    "- lenghth of the audio file (audio_file.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0ec8111-81ae-4f7e-9ba0-d707aff9f367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661794"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa14fca-11b0-4d01-8e05-cd67a5530302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
