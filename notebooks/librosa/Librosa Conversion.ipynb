{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09af93f9-a51d-413d-ad9b-44525f318e29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# All features extracted by Librosa \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29219ddf-5c23-4b99-a20a-58fb426d4e97",
   "metadata": {},
   "source": [
    "- Zero Crossing Rate, (mean and var)\n",
    "- Harmonics (mean and var)\n",
    "- Perceptrual (mean and var)\n",
    "- Tempo\n",
    "- Spectral Centroid (mean and var)\n",
    "- Spectral Rolloff (mean and var)\n",
    "- Spectral Bandwidth (mean and var)\n",
    "- Mel-Frequency Cepstral Coefficients (20 different coefficients) (mean and var)\n",
    "- Chroma (mean and var)\n",
    "- rms energy (mean and var)\n",
    "- lenghth of the audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92655337-c5e1-4dae-bf01-4f12b085e6e4",
   "metadata": {},
   "source": [
    "**Note on Librosa** \n",
    "- Librosa can open several audio formats beyond just WAV files. It uses backends like PySoundFile and audioread, which support formats such as MP3, FLAC, OGG, and more. Just ensure you have the necessary dependencies (like FFmpeg, libsndfile, etc.) installed for your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efeafaf-7477-495e-9b3f-9191d33cc497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Code for extracting features from one audio file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f0ba9-5aef-43e9-ae79-ec6d7fc0f1c4",
   "metadata": {},
   "source": [
    "Librosa Conversion code below ⤵  (for one audio file, as defined by the audio path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0649d52b-bb8b-4f44-a29b-c9830e9d7346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tford/code/zmokhtari89/k_means_klang/Notebooks/librosa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d5daf0a-ac0a-4d0e-bd94-f3143129f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>length_samples</th>\n",
       "      <th>zero_crossing_rate_mean</th>\n",
       "      <th>zero_crossing_rate_var</th>\n",
       "      <th>harmony_mean</th>\n",
       "      <th>harmony_var</th>\n",
       "      <th>perceptr_mean</th>\n",
       "      <th>perceptr_var</th>\n",
       "      <th>tempo</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jazz.00055.wav</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  length_samples  zero_crossing_rate_mean  \\\n",
       "0  jazz.00055.wav             0.0                      0.0   \n",
       "\n",
       "   zero_crossing_rate_var  harmony_mean  harmony_var  perceptr_mean  \\\n",
       "0                     0.0           0.0          0.0            0.0   \n",
       "\n",
       "   perceptr_var  tempo  spectral_centroid_mean  ...  mfcc_mean_16  \\\n",
       "0           0.0    0.0                     0.0  ...           0.0   \n",
       "\n",
       "   mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  mfcc_var_18  \\\n",
       "0          0.0           0.0          0.0           0.0          0.0   \n",
       "\n",
       "   mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20  \n",
       "0           0.0          0.0           0.0          0.0  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "general_path = '../../raw_data/Data'\n",
    "\n",
    "#when in the .py we will ned to use os.join__file__ and then set the path \n",
    "\n",
    "# Define the path to the audio file\n",
    "file_path = f'{general_path}/genres_original/jazz/jazz.00055.wav'\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#Step 1:  # Step 1: Load and trim the audio file\n",
    "#------------------------------------------------------------\n",
    "y, sr = librosa.load(str(file_path)) \n",
    "audio_file, _ = librosa.effects.trim(y)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#Step 2: Extract features. When relevant, calculate mean and variance\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# Length of the audio file (in samples)\n",
    "length = audio_file.shape[0]\n",
    "\n",
    "# Zero Crossing Rate\n",
    "zero_crossings = librosa.zero_crossings(audio_file, pad=False)\n",
    "zero_crossing_rate_mean = np.mean(zero_crossings)\n",
    "zero_crossing_rate_var = np.var(zero_crossings)\n",
    "\n",
    "# Harmonics & Percussive Components (HPSS)\n",
    "y_harm, y_perc = librosa.effects.hpss(audio_file)\n",
    "harmony_mean = np.mean(y_harm)\n",
    "harmony_var = np.var(y_harm)\n",
    "perceptr_mean = np.mean(y_perc)\n",
    "perceptr_var = np.var(y_perc)\n",
    "\n",
    "#Tempo: \n",
    "tempo_value, _ = librosa.beat.beat_track(y=audio_file, sr = sr) # a 2nd variable is created by the function, but we ignore it with the space' _ '.\n",
    "tempo = tempo_value.item()\n",
    "\n",
    "# Spectral Centroid\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=audio_file, sr=sr)[0]\n",
    "spectral_centroid_mean = np.mean(spectral_centroids)\n",
    "spectral_centroid_var = np.var(spectral_centroids)\n",
    "\n",
    "# Spectral Rolloff\n",
    "spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_file, sr=sr)[0]\n",
    "rolloff_mean = np.mean(spectral_rolloff)\n",
    "rolloff_var = np.var(spectral_rolloff)\n",
    "\n",
    "# Spectral Bandwidth\n",
    "bandwidth = librosa.feature.spectral_bandwidth(y=audio_file, sr=sr)\n",
    "spectral_bandwidth_mean = np.mean(bandwidth)\n",
    "spectral_bandwidth_var = np.var(bandwidth)\n",
    "\n",
    "#Chroma Frequencies (short-time fourier transform): \n",
    "hop_length = 5000   #Increase or decrease hop_length to change how granular you want your data to be\n",
    "chromagram = librosa.feature.chroma_stft(y=audio_file, sr=sr, hop_length=hop_length)\n",
    "chroma_stft_mean = np.mean(chromagram)\n",
    "chroma_stft_var = np.var(chromagram)\n",
    "\n",
    "# RMS Energy\n",
    "rms_values = librosa.feature.rms(y=audio_file)\n",
    "rms_mean = np.mean(rms_values)\n",
    "rms_var = np.var(rms_values)\n",
    "\n",
    "# Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "mfccs = librosa.feature.mfcc(y=audio_file, sr=sr)\n",
    "mfcc_means = np.mean(mfccs, axis=1)  # Array of 20 means\n",
    "mfcc_vars = np.var(mfccs, axis=1)     # Array of 20 variances\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#Step 3: Create a dictionary with all the features\n",
    "#------------------------------------------------------------\n",
    "\n",
    "data = {\n",
    "    'file_name': file_path.split('/')[-1],\n",
    "    'length_samples': length,\n",
    "    'zero_crossing_rate_mean': zero_crossing_rate_mean,\n",
    "    'zero_crossing_rate_var': zero_crossing_rate_var,\n",
    "    'harmony_mean': harmony_mean,\n",
    "    'harmony_var': harmony_var,\n",
    "    'perceptr_mean': perceptr_mean,\n",
    "    'perceptr_var': perceptr_var,\n",
    "    'tempo': tempo,\n",
    "    'spectral_centroid_mean': spectral_centroid_mean,\n",
    "    'spectral_centroid_var': spectral_centroid_var,\n",
    "    'spectral_rolloff_mean': rolloff_mean,\n",
    "    'spectral_rolloff_var': rolloff_var,\n",
    "    'spectral_bandwidth_mean': spectral_bandwidth_mean,\n",
    "    'spectral_bandwidth_var': spectral_bandwidth_var,\n",
    "    'chroma_stft_mean': chroma_stft_mean,\n",
    "    'chroma_stft_var': chroma_stft_var,\n",
    "    'rms_mean': rms_mean,\n",
    "    'rms_var': rms_var\n",
    "}\n",
    "\n",
    "# Add MFCC features as separate columns\n",
    "for i in range(len(mfcc_means)):\n",
    "    data[f'mfcc_mean_{i+1}'] = mfcc_means[i]\n",
    "    data[f'mfcc_var_{i+1}'] = mfcc_vars[i]\n",
    "\n",
    "# Step 4: Create a pandas DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "#Step 5: Apply Standard Scaling to all numeric columns \n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns]= scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1dc1a6-32ac-40dd-bd46-fe5251e771fc",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- Audio Loading and Trimming: The file is loaded and trimmed using librosa.load and librosa.effects.trim.\n",
    "- Feature Extraction: Various features are extracted (mean and variance where applicable) using librosa functions.\n",
    "- MFCCs: The MFCC coefficients are processed along axis 1 to yield a mean and variance for each of the 20 coefficients.\n",
    "- Dictionary Creation: All features are stored in a dictionary. The file name is extracted from the file path.\n",
    "- DataFrame Creation: A DataFrame is created from the dictionary, resulting in a single-row DataFrame that encapsulates all the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093f9aa-9d96-4525-aa55-d2bf5a9d3b74",
   "metadata": {},
   "source": [
    "# Code for extracting features for multiple audio files in a folder (and subfolders)\n",
    "- for various types of audio formats (see librosa note above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74c512-18ef-4987-9e9a-8feb56951d3d",
   "metadata": {},
   "source": [
    "**Optimized with parallell processing**  \n",
    "takes appox 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45f173bf-c59d-4931-90f3-5fb3214b5925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 3.22 s, total: 17.8 s\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#defining a function to extract features \n",
    "def extract_features(file_path):\n",
    "    # Load and trim the audio file\n",
    "    y, sr = librosa.load(file_path)\n",
    "    audio_file, _ = librosa.effects.trim(y)\n",
    "    \n",
    "    # Length (in samples)\n",
    "    length = audio_file.shape[0]\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zero_crossings = librosa.zero_crossings(audio_file, pad=False)\n",
    "    zero_crossings_rate_mean = np.mean(zero_crossings)\n",
    "    zero_crossings_rate_var = np.var(zero_crossings)\n",
    "    \n",
    "    # Harmonics & Percussive Components (HPSS)\n",
    "    y_harm, y_perc = librosa.effects.hpss(audio_file)\n",
    "    harmony_mean = np.mean(y_harm)\n",
    "    harmony_var = np.var(y_harm)\n",
    "    perceptr_mean = np.mean(y_perc)\n",
    "    perceptr_var = np.var(y_perc)\n",
    "    \n",
    "    # Tempo\n",
    "    tempo_value, _ = librosa.beat.beat_track(y=audio_file, sr=sr)\n",
    "    tempo = tempo_value.item()\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio_file, sr=sr)[0]\n",
    "    spectral_centroid_mean = np.mean(spectral_centroids)\n",
    "    spectral_centroid_var = np.var(spectral_centroids)\n",
    "    \n",
    "    # Spectral Rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_file, sr=sr)[0]\n",
    "    rolloff_mean = np.mean(spectral_rolloff)\n",
    "    rolloff_var = np.var(spectral_rolloff)\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=audio_file, sr=sr)\n",
    "    spectral_bandwidth_mean = np.mean(bandwidth)\n",
    "    spectral_bandwidth_var = np.var(bandwidth)\n",
    "    \n",
    "    # Chroma Frequencies\n",
    "    hop_length = 5000  # Adjust for granularity\n",
    "    chromagram = librosa.feature.chroma_stft(y=audio_file, sr=sr, hop_length=hop_length)\n",
    "    chroma_mean = np.mean(chromagram)\n",
    "    chroma_var = np.var(chromagram)\n",
    "    \n",
    "    # RMS Energy\n",
    "    rms_values = librosa.feature.rms(y=audio_file)\n",
    "    rms_mean = np.mean(rms_values)\n",
    "    rms_var = np.var(rms_values)\n",
    "    \n",
    "    # MFCCs (20 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_file, sr=sr)\n",
    "    mfcc_means = np.mean(mfccs, axis=1)\n",
    "    mfcc_vars = np.var(mfccs, axis=1)\n",
    "    \n",
    "    # Build feature dictionary\n",
    "    features = {\n",
    "        'file_name': os.path.basename(file_path),\n",
    "        'length_samples': length,\n",
    "        'zero_crossings_rate_mean': zero_crossings_rate_mean,\n",
    "        'zero_crossings_rate_var': zero_crossings_rate_var,\n",
    "        'harmony_mean': harmony_mean,\n",
    "        'harmony_var': harmony_var,\n",
    "        'perceptr_mean': perceptr_mean,\n",
    "        'perceptr_var': perceptr_var,\n",
    "        'tempo': tempo,\n",
    "        'spectral_centroid_mean': spectral_centroid_mean,\n",
    "        'spectral_centroid_var': spectral_centroid_var,\n",
    "        'rolloff_mean': rolloff_mean,\n",
    "        'rolloff_var': rolloff_var,\n",
    "        'spectral_bandwidth_mean': spectral_bandwidth_mean,\n",
    "        'spectral_bandwidth_var': spectral_bandwidth_var,\n",
    "        'chroma_mean': chroma_mean,\n",
    "        'chroma_var': chroma_var,\n",
    "        'rms_mean': rms_mean,\n",
    "        'rms_var': rms_var\n",
    "    }\n",
    "    \n",
    "    # Add MFCC features (20 coefficients)\n",
    "    for i in range(len(mfcc_means)):\n",
    "        features[f'mfcc_mean_{i+1}'] = mfcc_means[i]\n",
    "        features[f'mfcc_var_{i+1}'] = mfcc_vars[i]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Define main folder path containing subfolders with audio files\n",
    "main_folder_path = '../../raw_data/Data/genres_original'\n",
    "\n",
    "# Collect file paths from all subfolders using os.walk()\n",
    "file_paths = []\n",
    "for root, dirs, files in os.walk(main_folder_path):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.wav', '.mp3', '.flac')):\n",
    "            file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "# Use joblib to process files in parallel\n",
    "data_list = Parallel(n_jobs=-1)(delayed(extract_features)(fp) for fp in file_paths)\n",
    "\n",
    "# Create a DataFrame from the list of feature dictionaries\n",
    "df= pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5c0f4-d1ec-4f40-8d0b-eef073987f35",
   "metadata": {},
   "source": [
    "### Scaling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef255d-3a22-4db7-aedd-09a83a4a07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Scaling to all numeric columns \n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns]= scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb32d339-bb1c-4c95-8188-5b4d335ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a csv file \n",
    "# df.to_csv('features_30_sec_taitest.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b610e-d229-4d41-afd8-7eb4b4b652bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
